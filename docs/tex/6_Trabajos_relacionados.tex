\capitulo{6}{Trabajos relacionados}

En esta Sección se van a comentar los trabajos relacionados desde dos ópticas, la primera de ellas desde el \textit{Machine Learning As A Service}, MLaaS; y la segunda desde el punto de vista del Aprendizaje Semi-Supervisado Seguro (\textit{Safe-SSL}).

\section{\textit{Machine Learning As A Service}}
\subsection{\textit{Frameworks} y bibiotecas}\label{related:frameworks}
Aunque está categorizado con dos términos, se puede entender un \textit{framework} de \textit{Machine Learning} como una herramienta, biblioteca o interfaz que proporciona a los desarrolladores facilidades para crear modelos de aprendizaje automático.

\begin{enumerate}
\item \textit{\textbf{Scikit-Learn}.}
Coloquialmente conocido como <<Sklearn>>, es la biblioteca más útil y robusta para aprendizaje automático implementada en Python. Se trata de un \textit{software open source}. Entre la multitud de algoritmos que provee, destacan varios para problemas de clasificación, regresión y \textit{clustering}; incluyéndose además máquinas de soporte vectorial (SVM), \textit{random forests}, \textit{gradient boosting}, \textit{k-means} y DBSCAN.

Si bien proporciona soporte para el aprendizaje semi-supervisado, este es mínimo, pudiendo encontrar únicamente \textit{Self-Trainig} entre los clasificadores disponibles.

A pesar de estar escrito en su mayor parte en Python, y el uso que le da a la biblioteca de NumPy\footnote{biblioteca de Python que da soporte al uso de vectores y matrices con una gran dimensionalidad. Además proporciona una gran colección de funciones matemáticas de alto nivel para operar con ellas.} para el cálculo de operaciones algebraicas en entornos de alto rendimiento, el \textit{core} de la biblioteca está escrito en Cython\footnote{Compilador estático optimizado tanto para Python como para el lenguaje Cython extendido, (basado en Pyrex). Permitiendo escribir extensiones de C para Python de manera tan sencilla que casi parece Python.} para mejorar el rendimiento. 

\item \textbf{\textit{Tensor Flow}.}
Biblioteca desarrollada por Google, sigue una filosofía \textit{open source}. Tensor Flow es utilizada para el cálculo numérico utilizando gráficos de flujo. En las gráficas los nodos representan operaciones matemáticas mientras que los bordes representan las matrices de datos multidimensionales.

Mediante su arquitectura flexible permite la implementación del cálculo en una o varias CPU o GPU, en servidores, o equipos móviles, todo con una sola API\footnote{Conjunto de definiciones y protocolos que se utiliza para desarrollar e integrar el \textit{software} de  las aplicaciones, permitiendo la comunicación entre dos aplicaciones a través deun conjunto de reglas.}. Su diseño esta principalmente enfocado para la resolución de problemas mediante redes neuronales, pero es lo suficientemente general como para ser aplicable a una amplia variedad de dominios.

\item \textbf{\textit{Torch}.}
Marco de cálculo científico con amplio soporte para algoritmos de aprendizaje automático el cual da prioridad al uso de GPU sobre CPU, se trata de un \textit{software open source}. Una de sus características principales es el rendimiento y eficiencia que proporciona, esto se debe a que está escrito en LuaJIT y una implementación subyacente de C/CUDA.

\item \textbf{\textit{Theano}.}
biblioteca de Python la cual da soporte a la definición  de expresiones matemáticas empleadas en aprendizaje automático, la optimzación de estas expresiones y la evaluación de la eficiencia con el uso de GPU. Siendo capaz de rivalizar implementaciones escritas en C. Theano está distribuida bajo licencia BSD\footnote{Licencia de \textit{software} libre permisiva, de igual manera que la licencia MIT, posee menos restricciones que GPL, siendo muy cercana al dominio público.}.

\item \textbf{\textit{Veles}.}
Escrito en C++, sus aplicaciones se encuentran dentro del marco del aprendizaje profundo. A pesar de ello utiliza Python para la automatización y coordinación de sus nodos. Sus objetivos principales son la flexibilidad y el rendimiento. Permitiendo la normalización de los datos antes de introducirlos en un cluster.

Veles permite entrenar redes convolucionales, redes recurrentes, redes totalmente conectadas y otras topologías populares.

\item \textbf{\textit{H2O}.}
Marco de aprendizaje automático \textit{open source}. Orientado principalmente a negocios, implementa análisis predictivo para ayudar a la toma de decisiones basadas en datos y conocimientos. Proporciona herramientas únicas como el soporte agnóstico de bases de datos, una interfaz WebUI. 

H2O provee de modelos y soporte para Python, R, Java, JSON, Scala, JavaScript. Su \textit{core} está escrito en Java.

\end{enumerate}

\subsection{\textit{Proveedores de MLaaS}}\label{related:MLaaS}
El Aprendizaje Automático como servicio (MLaaS por sus siglas en inglés), es una tecnología de aprendizaje automático que es habitualmente adquirida de un tercero. Su funcionamiento es similar a SaaS (\textit{Software as a Service}) o PaaS (\textit{Platform as a Service}), \textit{i.e.} un usuario utiliza los servicios de un tercero en lugar de los suyos propios.

\begin{enumerate}
\item \textbf{\textit{Amazon Machine Learning}.}
Servicio ofrecido por Amazon el cual proporciona todas las herramientas necesarias para utilizar modelos de aprendizaje automático sin necesidad de conocer todos los detalles y configuraciones de estos. No quedándose ahí, proporciona herramientas de análisis de datos y modelos pre-entrenados para casos de uso habituales como detección de fraude en aplicaciones móviles.

Encaja a la perfección con proyectos o necesidades que necesitan interacción en tiempo real. A pesar de que únicamente proporciona soporte a problemas de clasificación binaria o multi-etiqueta, y regresión; una de sus funcionalidades más <<potentes>> viene dada por la capacidad del propio servicio de seleccionar el algoritmo que mejor se adecua al problema dado.

\item \textbf{\textit{SageMaker}.}
Entorno de aprendizaje automático con el objetivo de simplificar el trabajo a los científicos de datos, para ello proporciona herramientas que permiten la creación y despliegue de forma rápida de modelos.

Proporciona multitud de modelos que su predecesor (Amazon \textit{Machine Learning}) no poseía, como es el caso del aprendizaje no supervisado. Siendo la evolución natural para aquellas empresas que ya utilizan los servicios web de Amazon (AWS).

\item \textbf{\textit{Microsoft Azure AI Platform}.}
Proporciona una plataforma unificada con todas las API correspondientes a técnicas de aprendizaje automático y servicios de infraestructura en Azure.

Destaca \textit{Azure Machine Learning} como entrono por excelencia para el manejo de conjuntos de datos, creación, entrenamiento y despliegue de modelos. Permitiendo que desde la interfaz web y con muy poca codificación necesaria, se puedan crear modelos. Ofreciendo soporte a cerca de cien métodos para problemas de clasificación binaria y multi-etiqueta, detección de anomalías, regresión, recomendación, análisis de textos, y como único algoritmo de \textit{clustering}, \textit{k-means}.

\item \textbf{\textit{Google Cloud ML}.}
Plataforma de \textit{Machine Learning} basada en la nube que sugiere un enfoque sin código para construir soluciones basadas en datos. Fue diseñado para que tanto los recién llegados como los ingenieros fueran capaces de construir modelos personalizados. Como es habitual, ofrece también un conjunto de modelos pre-construidos, a través de un conjunto de API.

\item \textbf{\textit{IBM Watson Machine Learning Studio}.}
Aporta una interfaz de procesamiento de datos y creación de modelos totalmente automatizada que apenas necesita formación para empezar a procesar los datos, preparar los modelos y desplegarlos en producción.

La parte automatizada es capaz de resolver problemas de clasificación binaria y multi-etiqueta, y regresión. Permitiendo la opción de que el usuario elija el modelo de \textit{Machine Learning} deseado o que sea el propio sistema el que infiera el que considera mejor a partir de los datos.

\item \textbf{\textit{UBUMLaaS}}. La Universidad de Burgos también dispone de su propio servicio de \textit{MLaaS}, ver~\ref{UBUMLaaS}.

\end{enumerate}
\clearpage
\subsection{Comparativa entre MLaaS y UBUMLaaS}
Tal y como se puede apreciar en la tabla~\ref{table:Comp-MLaaS}, existen numerosos servicios soportados por los principales proveedores de \textit{Machine Learning as a Service}, \textit{\textit{e.g.}} todos ellos permiten el etiquetado de datos con técnicas de clasificación y regresión. 

Todas las herramientas anteriormente descritas han sido comparadas contra \textit{UBUMLaaS}. 

\begin{table}[b]
\centering
\small
\begin{tabular}{lccccc}
\rowcolor[rgb]{0.753,0.753,0.753} \diagbox{Soporte}{Servicios}                                                                       & \begin{tabular}[c]{@{}>{\cellcolor[rgb]{0.753,0.753,0.753}}c@{}}Amazon ML\\SageMaker\end{tabular} & \begin{tabular}[c]{@{}>{\cellcolor[rgb]{0.753,0.753,0.753}}c@{}}Microsoft \\Azure\end{tabular} & \begin{tabular}[c]{@{}>{\cellcolor[rgb]{0.753,0.753,0.753}}c@{}}Google \\AI Platform\end{tabular} & \begin{tabular}[c]{@{}>{\cellcolor[rgb]{0.753,0.753,0.753}}c@{}}IBM \\Watson\end{tabular} & UBUMLaaS  \\
\toprule
\begin{tabular}[c]{@{}l@{}}Aprendizaje \\Supervisado\end{tabular}                                                                            & X                                                                                                 & X                                                                                              & X                                                                                                 & X                                                                                           & X         \\
\rowcolor[rgb]{0.839,0.839,0.839} \begin{tabular}[c]{@{}>{\cellcolor[rgb]{0.839,0.839,0.839}}l@{}}Aprendizaje \\Semi-Supervisado\end{tabular} & X                                                                                                 & X                                                                                              &                                                                                        X           &                                                                                           & X         \\
\begin{tabular}[c]{@{}l@{}}Aprendizaje \\No Supervisado\end{tabular}                                                                         & X                                                                                                 & X                                                                                              & X                                                                                                 &                                                                                           &           \\
\rowcolor[rgb]{0.839,0.839,0.839} Clasificación                                                                                              & X                                                                                                 & X                                                                                              & X                                                                                                 & X                                                                                         & X         \\
Regresión                                                                                                                                    & X                                                                                                 & X                                                                                              & X                                                                                                 & X                                                                                         & X         \\
\rowcolor[rgb]{0.839,0.839,0.839} Clustering                                                                                                 & X                                                                                                 & X                                                                                              &                                                                                                  & X                                                                                         & X         \\
Recomendaciones                                                                                                                              & X                                                                                                 & X                                                                                              & X                                                                                                 &                                                                                           &           \\
\rowcolor[rgb]{0.839,0.839,0.839} \begin{tabular}[c]{@{}>{\cellcolor[rgb]{0.839,0.839,0.839}}l@{}}Etiquetado \\de datos\end{tabular}         & X                                                                                                 & X                                                                                              & X                                                                                                 & X                                                                                         & X         \\
\begin{tabular}[c]{@{}l@{}}Algoritmos \\pre-implementados\end{tabular}                                                                       & X                                                                                                 & X                                                                                              & X                                                                                                 &                                                                                           & X        \\
\rowcolor[rgb]{0.839,0.839,0.839} \begin{tabular}[c]{@{}>{\cellcolor[rgb]{0.839,0.839,0.839}}l@{}}Coste (USD/h)\end{tabular}         & 0,408 & 0,099 & 1,375                                                                                          & 0,46                                                                                        & 0         \\
\bottomrule
\end{tabular}
\caption{Comparativa general entre proveedores de MLaaS.}\label{table:Comp-MLaaS}
\end{table}
\clearpage
\section{Aprendizaje Semi-Supervisado Seguro}
A pesar de que se han hecho multitud de aproximaciones y estudios sobre Clasificación Semi-Supervisada~\cite{jesper2020survey}, los prototipos son habitualmente clasificados dependiendo de diferentes suposiciones relacionadas con la distribución de los ejemplos etiquetados y no etiquetados. Habitualmente los modelos se basan en la suposición de existencia de matrices y/o \textit{clusters}. Si los datos corresponden a un \textit{manifold}\footnote{Término técnico que se utiliza para clasificar espacios de dimensión arbitraria. Para cada número entero existe un espacio plano llamado espacio euclidiano que tiene características muy similares al plano cartesiano. Esencialmente una generalización del espacio euclidiano tal que localmente (áreas pequeñas) es aproximadamente lo mismo que el espacio euclidiano pero el espacio entero no tiene las mismas propiedades del espacio euclidiano cuando se observa en su totalidad.} de menor dimensionalidad que el espacio de entrada, es adecuado para suposición de \textit{manifold}~\cite{wang2011solution}.

Siguiendo con esta idea en mente, la construcción de grafos permite determinar el comportamiento de los modelos, ya que dos prototipos conectados por una arista fuerte probablemente indique que ambos prototipos poseen la misma etiqueta~\cite{wang2013semi}. La suposición de \textit{cluster} supone que prototipos <<similares>> deberían tener las mismas etiquetas.

La aplicación de técnicas de <<autoetiquetado>> son aquellas que aprovechan un clasificador supervisado para etiquetar la clase desconocida y no hacen suposiciones específicas acerca de los datos de entrada~\cite{triguero2015self}. Para ello lo habitual es entrenar un clasificador o un conjunto de ellos y posteriormente aprovechar el conocimiento adquirido por este(os) clasificador(es) para entrenar uno nuevo que produzca mejores resultados~\cite{blum1998combining, zhou2005tri}.

Todos los modelos con los que habitualmente se trabaja se basan únicamente en el uso de aquellas instancias que se encuentran etiquetadas para obtener una mayor diversidad en los clasificadores, sin pararse a utilizar la gran y abundante información que se encuentra dentro de los prototipos no etiquetados~\cite{zhao2021safe}. Pero es aquí donde surge el problema real, no se tiene en cuenta que estos clasificadores iterativos también introducen ruido en el conjunto de datos etiquetados, es decir, clasifican mejor o peor pero no son seguros; todo ello propicia que en determinadas ocasiones el rendimiento empeore.

En~\cite{triguero2014characterization} se propone el análisis de características de una gran variedad de filtros de ruido de diferente naturaleza, con el objetivo de mejorar el auto-entrenamiento en aprendizaje semi-supervisado orientado a problemas de clasificación. Muchos de los filtros propuestos ya se habían estudiado previamente en aprendizaje supervisado, pero el proceso de filtrado puede ser más difícil de realizar cuando se trata de problemas de aprendizaje semi-supervisado debido al reducido número de instancias que se poseen etiquetadas.

\cite{triguero2014characterization} comprueba como los filtros <<globales>>, algoritmos CF e IPF, destacan como la familia de filtros con mejor rendimiento, mostrando que la concordancia de hipótesis de varios clasificadores también es robusta cuando se reduce la proporción de datos etiquetados disponibles. La mayoría de los enfoques locales necesitan más datos etiquetadas para rendir mejor. El uso de estos filtros ha dado lugar a un mejor rendimiento que el logrado por métodos de auto-formación como son SETRED y SNNRCE. Obteniendo como conclusión que el uso de filtros <<globales>> es muy recomendable en el campo en el que se enmarca tanto este como el citado trabajo.

Con el fin de trabajar con aprendizaje semi-supervisado seguro, en~\cite{zhao2021safe} se propone una nueva forma de trabajar con clasificadores supervisados en un \textit{ensemble}, los cuales a partir de múltiples iteraciones y pasadas sobre el conjunto de datos etiquetados lo acabarán etiquetando de forma segura. Para ello los clasificadores son entrenados con conjuntos de datos extraídos de los prototipos etiquetados y los cuales han sido seleccionados entre aquellos que poseen una baja ambigüedad. Posteriormente se etiquetas aquellos prototipos para los cuales los clasificadores acuerdan mediante mayoría de la clase a la que corresponde y se reentrenan los modelos.

De la misma forma que se acaba de ver cómo hay trabajos en la literatura acerca de mejorar los métodos ya existentes de clasificación semi-supervisada, también existen métodos basados en \textit{clusters} los cuáles eran brevemente introducidos al principio de esta sección. Uno de los mayores problemas que se encontraban éstos métodos era el poder generalizar para cualquier conjunto de datos independientemente de cuál fuese su distribución~\cite{adankon2011help, gan2013using}.

Gracias al trabajo de~\cite{rodriguez2014clustering} en el cual propone que para todo prototipo del conjunto de datos global (etiquetado y no etiquetado) el algoritmo calcula dos valores, su densidad local y la distancia a los puntos de mayor densidad local. Permitiendo descubrir la estructura real del espacio de datos, sin importar si la distribución de los datos es esférica o no, puede ser descubierta haciendo que cada prototipo apunte a su prototipo más cercano con una densidad local más alta.

Con base esta última aproximación, en~\cite{wu2018self} se propone una aproximación que integra la estructura descubierta basada en picos de densidad junto con el proceso de entrenamiento semi-supervisado, mediante el entrenamiento iterativo de un clasificador supervisado. Obteniendo las ventajas de:
\begin{itemize}
\item No se encuentra limitado por la distribución inicial de los datos etiquetados y del conjunto de datos general.
\item Es un modelo constrictivo sin condiciones anteriores.
\item Es un modelo adecuado para mejorar el rendimiento de cualquier algoritmo supervisado mediante el uso de grandes cantidades de datos.
\end{itemize}