@book{koza92,
  author    = {Koza, John R.},
  title     = {Genetic Programming: On the Programming of Computers by Means of Natural Selection},
  publisher = {MIT Press},
  year      = {1992}
}


@misc{IBM-WhatisDataMining,
  title   = {What is Data Mining?},
  url     = {https://www.ibm.com/cloud/learn/data-mining},
  journal = {IBM},
  author  = {IBM Cloud Education},
  year = {2021}
}


@article{bortolot2005,
  title     = {Estimating forest biomass using small footprint LiDAR data: An individual tree-based approach that incorporates training data},
  author    = {Bortolot, Zachary J and Wynne, Randolph H},
  journal   = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume    = {59},
  number    = {6},
  pages     = {342--360},
  year      = {2005},
  publisher = {Elsevier}
}


@incollection{KOTU201517,
  title     = {Chapter 2 - Data Mining Process},
  editor    = {Vijay Kotu and Bala Deshpande},
  booktitle = {Predictive Analytics and Data Mining},
  publisher = {Morgan Kaufmann},
  address   = {Boston},
  pages     = {17-36},
  year      = {2015},
  isbn      = {978-0-12-801460-8},
  doi       = {https://doi.org/10.1016/B978-0-12-801460-8.00002-1},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780128014608000021},
  author    = {Vijay Kotu and Bala Deshpande},
  keywords  = {CRISP, KDD, data mining process, prior knowledge, modeling, data preparation, evaluation, application},
  abstract  = {Successfully uncovering patterns using data mining is an iterative process. Chapter 2 provides a framework to solve the data mining problem. The five-step process outlined in this chapter provides guidelines on gathering subject matter expertise; exploring the data with statistics and visualization; building a model using data mining algorithms; testing the model and deploying it in a production environment; and finally reflecting on new knowledge gained in the cycle. Over the years of evolution of data mining practices, different frameworks for the data mining process have been put forward by various academic and commercial bodies, like the Cross Industry Standard Process for Data Mining, knowledge discovery in databases, etc. These data mining frameworks exhibit common characteristics and hence we will be using a generic framework closely resembling the CRISP process.}
}


@inproceedings{Chapman2000CRISPDM1S,
  title  = {CRISP-DM 1.0: Step-by-step data mining guide},
  author = {Peter Chapman and Janet Clinton and Randy Kerber and Tom Khabaza and Thomas P. Reinartz and Colin Shearer and Richard Wirth},
  year   = {2000}
}


@article{CRAVEN1997211,
title = {Using neural networks for data mining},
journal = {Future Generation Computer Systems},
volume = {13},
number = {2},
pages = {211-229},
year = {1997},
note = {Data Mining},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(97)00022-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X97000228},
author = {Mark W. Craven and Jude W. Shavlik},
keywords = {Machine learning, Neural networks, Rule extraction, Comprehensible models, Decision trees, Perceptrons},
abstract = {Neural networks have been successfully applied in a wide range of supervised and unsupervised learning applications. Neural-network methods are not commonly used for data-mining tasks, however, because they often produce incomprehensible models and require long training times. In this article, we describe neural-network learning algorithms that are able to produce comprehensible models, and that do not require excessive training times. Specifically, we discuss two classes of approaches for data mining with neural networks. The first type of approach, often called rule extraction, involves extracting symbolic models from trained neural networks. The second approach is to directly learn simple, easy-to-understand networks. We argue that, given the current state-of-the-art, neural-network methods deserve a place in the tool boxes of data-mining specialists.}
}


@article{hand2007principles,
  title={Principles of data mining},
  author={Hand, David J},
  journal={Drug safety},
  volume={30},
  number={7},
  pages={621--622},
  year={2007},
  publisher={Springer}
}


@inproceedings{guo2003knn,
  title={KNN model-based approach in classification},
  author={Guo, Gongde and Wang, Hui and Bell, David and Bi, Yaxin and Greer, Kieran},
  booktitle={OTM Confederated International Conferences" On the Move to Meaningful Internet Systems"},
  pages={986--996},
  year={2003},
  organization={Springer}
}


@misc{sanchez_2020, title={¿Cómo aprenden las máquinas? Machine Learning y sus diferentes tipos}, url={https://datos.gob.es/es/blog/como-aprenden-las-maquinas-machine-learning-y-sus-diferentes-tipos}, journal={¿Cómo aprenden las máquinas? machine learning y sus diferentes tipos}, publisher={Gobierno de España}, author={Sanchez, Jose Antonio}, year={2020}, month={Aug}
} 
 
@misc{technovert_2020, title={Introduction to machine learning}, url={https://technovert.com/introduction-to-machine-learning}, journal={Technovert}, author={Technovert}, year={2020}
}

@article{learned2014introduction,
  title={Introduction to supervised learning},
  author={Learned-Miller, Erik G},
  journal={I: Department of Computer Science, University of Massachusetts},
  year={2014}
}

@misc{supervised_learning_mathworks_inc, title={Supervised Learning}, url={https://www.mathworks.com/discovery/supervised-learning.html}, journal={MATLAB & Simulink}, author={Mathworks Inc}
}

@article{bengio2012unsupervised,
  title={Unsupervised feature learning and deep learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron C and Vincent, Pascal},
  journal={CoRR, abs/1206.5538},
  volume={1},
  pages={2012},
  year={2012}
}

@misc{unsupervised_learning_clustering, title={Clustering in Unsupervised Machine Learning}, url={https://www.section.io/engineering-education/clustering-in-unsupervised-ml/}, journal={Section}, author={Onesmus Mbaabu}
} 

@article{li2002unsupervised,
  title={Unsupervised learning with mixed numeric and nominal data},
  author={Li, Cen and Biswas, Gautam},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={14},
  number={4},
  pages={673--690},
  year={2002},
  publisher={IEEE}
}

@incollection{zhou2014semi,
  title={Semi-supervised learning},
  author={Zhou, Xueyuan and Belkin, Mikhail},
  booktitle={Academic Press Library in Signal Processing},
  volume={1},
  pages={1239--1269},
  year={2014},
  publisher={Elsevier}
}

@misc{javatpoint_semisupervised, title={Introduction to Semi-Supervised Learning - Javatpoint}, url={https://www.javatpoint.com/semi-supervised-learning}, journal={www.javatpoint.com}, author={JavaTPoint}
} 

@article{thekumparampil2018attention,
  title={Attention-based graph neural network for semi-supervised learning},
  author={Thekumparampil, Kiran K and Wang, Chong and Oh, Sewoong and Li, Li-Jia},
  journal={arXiv preprint arXiv:1803.03735},
  year={2018}
}

@article{olvera2010review,
  title={A review of instance selection methods},
  author={Olvera-L{\'o}pez, J Arturo and Carrasco-Ochoa, J Ariel and Mart{\'\i}nez-Trinidad, J Francisco and Kittler, Josef},
  journal={Artificial Intelligence Review},
  volume={34},
  number={2},
  pages={133--143},
  year={2010},
  publisher={Springer}
}

@article{wilson1972asymptotic,
  title={Asymptotic properties of nearest neighbor rules using edited data},
  author={Wilson, Dennis L},
  journal={IEEE Transactions on Systems, Man, and Cybernetics},
  number={3},
  pages={408--421},
  year={1972},
  publisher={IEEE}
}

@article{hart1968condensed,
  title={The condensed nearest neighbor rule (corresp.)},
  author={Hart, Peter},
  journal={IEEE transactions on information theory},
  volume={14},
  number={3},
  pages={515--516},
  year={1968},
  publisher={Citeseer}
}

@article{gates1972reduced,
  title={The reduced nearest neighbor rule (corresp.)},
  author={Gates, Geoffrey},
  journal={IEEE transactions on information theory},
  volume={18},
  number={3},
  pages={431--433},
  year={1972},
  publisher={IEEE}
}

@article{brighton2002advances,
  title={Advances in instance selection for instance-based learning algorithms},
  author={Brighton, Henry and Mellish, Chris},
  journal={Data mining and knowledge discovery},
  volume={6},
  number={2},
  pages={153--172},
  year={2002},
  publisher={Springer}
}

@article{barandela2005decision,
  title={Decision boundary preserving prototype selection for nearest neighbor classification},
  author={Barandela, Ricardo and Ferri, Francesc J and S{\'a}nchez, J Salvador},
  journal={International Journal of Pattern Recognition and Artificial Intelligence},
  volume={19},
  number={06},
  pages={787--806},
  year={2005},
  publisher={World Scientific}
}

@article{ritter1975algorithm,
  title={An algorithm for a selective nearest neighbor decision rule (corresp.)},
  author={Ritter, G and Woodruff, H and Lowry, S and Isenhour, T},
  journal={IEEE Transactions on Information Theory},
  volume={21},
  number={6},
  pages={665--669},
  year={1975},
  publisher={IEEE}
}

@article{wilfong1992nearest,
  title={Nearest neighbor problems},
  author={Wilfong, Gordon},
  journal={International Journal of Computational Geometry \& Applications},
  volume={2},
  number={04},
  pages={383--416},
  year={1992},
  publisher={World Scientific}
}

@misc{mlpipeline2018, title={AutoML for building simple to complex ML pipelines}, url={https://hub.packtpub.com/automl-build-machine-learning-pipeline-tutorial/}, journal={Packt Hub}, author={-, Sunith Shetty}, year={2018}, month={Sep}
} 

@article{palmer2011data,
  title={Data mining: Machine learning and statistical techniques},
  author={Palmer, Alfonso and Jim{\'e}nez, Rafael and Gervilla, Elena},
  journal={Knowledge-Oriented Applications in Data Mining, Prof. Kimito Funatsu (Ed.)},
  pages={373--396},
  year={2011}
}

@book{potomac1999introduction,
  title={Introduction to data mining and knowledge discovery},
  author={Potomac Two Crows Corporation},
  year={1999},
  publisher={Two Crows}
}

@inproceedings{blum1998combining,
  title={Combining labeled and unlabeled data with co-training},
  author={Blum, Avrim and Mitchell, Tom},
  booktitle={Proceedings of the eleventh annual conference on Computational learning theory},
  pages={92--100},
  year={1998}
}


@inproceedings{ghahramani1994supervised,
  title={Supervised learning from incomplete data via an EM approach},
  author={Ghahramani, Zoubin and Jordan, Michael I},
  booktitle={Advances in neural information processing systems},
  pages={120--127},
  year={1994}
}

@inproceedings{ratsaby1995learning,
  title={Learning from a mixture of labeled and unlabeled examples with parametric side information},
  author={Ratsaby, Joel and Venkatesh, Santosh S},
  booktitle={Proceedings of the eighth annual conference on Computational learning theory},
  pages={412--417},
  year={1995}
}

@article{zhou2005tri,
  title={Tri-training: Exploiting unlabeled data using three classifiers},
  author={Zhou, Zhi-Hua and Li, Ming},
  journal={IEEE Transactions on knowledge and Data Engineering},
  volume={17},
  number={11},
  pages={1529--1541},
  year={2005},
  publisher={IEEE}
}

@article{dasgupta2002pac,
  title={PAC generalization bounds for co-training},
  author={Dasgupta, Sanjoy and Littman, Michael L and McAllester, David},
  journal={Advances in neural information processing systems},
  volume={1},
  pages={375--382},
  year={2002},
  publisher={MIT; 1998}
}

@article{triguero2015self,
  title={Self-labeled techniques for semi-supervised learning: taxonomy, software and empirical study},
  author={Triguero, Isaac and Garc{\'\i}a, Salvador and Herrera, Francisco},
  journal={Knowledge and Information systems},
  volume={42},
  number={2},
  pages={245--284},
  year={2015},
  publisher={Springer}
}

@article{jesper2020survey,
author = {Engelen, Jesper and Hoos, Holger},
year = {2020},
month = {02},
pages = {},
title = {A survey on semi-supervised learning},
volume = {109},
journal = {Machine Learning},
doi = {10.1007/s10994-019-05855-6}
}

@inproceedings{yarowsky1995unsupervised,
  title={Unsupervised word sense disambiguation rivaling supervised methods},
  author={Yarowsky, David},
  booktitle={33rd annual meeting of the association for computational linguistics},
  pages={189--196},
  year={1995}
}

@article{dempster1977maximum,
  title={Maximum likelihood from incomplete data via the EM algorithm},
  author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={39},
  number={1},
  pages={1--22},
  year={1977},
  publisher={Wiley Online Library}
}

@inproceedings{zhou2004democratic,
  title={Democratic co-learning},
  author={Zhou, Yan and Goldman, Sally},
  booktitle={16th IEEE International Conference on Tools with Artificial Intelligence},
  pages={594--602},
  year={2004},
  organization={IEEE}
}

@article{wilson2000reduction,
  title={Reduction techniques for instance-based learning algorithms},
  author={Wilson, D Randall and Martinez, Tony R},
  journal={Machine learning},
  volume={38},
  number={3},
  pages={257--286},
  year={2000},
  publisher={Springer}
}
